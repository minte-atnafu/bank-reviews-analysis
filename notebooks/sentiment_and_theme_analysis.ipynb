{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec5dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725a422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/bank_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3dbfdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mintesinot\\bank-reviews-analysis\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d005aa169b834f5d9ade8aabaafeca20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mintesinot\\bank-reviews-analysis\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mintesinot\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b96c5810e5c4419979a8b12900246df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bd8f2ceea44faeb23b84c00ee156c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226fc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return 'NEUTRAL', 0.5\n",
    "    result = classifier(text[:512])[0]  # Truncate to 512 tokens\n",
    "    label = result['label'].upper()\n",
    "    score = result['score']\n",
    "    return label, score\n",
    "\n",
    "df['sentiment_label'], df['sentiment_score'] = zip(*df['review'].apply(get_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e94af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thematic Analysis\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "699bffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for thematic analysis\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['processed_text'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d9b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=100)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_text'])\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b259caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual theme clustering\n",
    "themes = {\n",
    "    'CBE': {\n",
    "        'Account Access Issues': ['login error', 'authentication fail', 'pin issue'],\n",
    "        'Transaction Performance': ['slow transfer', 'transfer fail', 'loading delay'],\n",
    "        'User Interface': ['intuitive ui', 'poor summary', 'ui change'],\n",
    "        'Customer Support': ['support unresponsive', 'contact issue'],\n",
    "        'Feature Requests': ['fingerprint login', 'qr code', 'budget tool']\n",
    "    },\n",
    "    'BOA': {\n",
    "        'Account Access Issues': ['login fail', 'zero balance', 'authentication bug'],\n",
    "        'Transaction Performance': ['slow load', 'transfer error', 'et-switch fail'],\n",
    "        'User Interface': ['poor design', 'logo issue', 'unresponsive ui'],\n",
    "        'Customer Support': ['support delay', 'unresolved issue'],\n",
    "        'Feature Requests': ['fingerprint login', 'faster transfer']\n",
    "    },\n",
    "    'Dashen': {\n",
    "        'Account Access Issues': ['login issue', 'account access'],\n",
    "        'Transaction Performance': ['transfer speed', 'payment delay'],\n",
    "        'User Interface': ['clean ui', 'navigation ease'],\n",
    "        'Customer Support': ['support response', 'helpdesk'],\n",
    "        'Feature Requests': ['biometric login', 'transaction limit']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d401d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign themes to reviews\n",
    "def assign_themes(text, bank):\n",
    "    doc = nlp(text.lower())\n",
    "    review_themes = []\n",
    "    for theme, keywords in themes[bank].items():\n",
    "        if any(keyword in text.lower() for keyword in keywords):\n",
    "            review_themes.append(theme)\n",
    "    return ', '.join(review_themes) if review_themes else 'Other'\n",
    "\n",
    "df['theme'] = df.apply(lambda x: assign_themes(x['review'], x['bank']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146f752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sentiment and theme analysis to data/sentiment_themes.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results in the 'data' folder\n",
    "output_df = df[['review_id', 'review', 'sentiment_label', 'sentiment_score', 'theme']]\n",
    "output_df.to_csv('../data/sentiment_themes.csv', index=False)\n",
    "print(\"Saved sentiment and theme analysis to data/sentiment_themes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5276ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank    rating\n",
      "BOA     1         0.977844\n",
      "        2         0.935626\n",
      "        3         0.961892\n",
      "        4         0.958368\n",
      "        5         0.959053\n",
      "CBE     1         0.963464\n",
      "        2         0.980620\n",
      "        3         0.976234\n",
      "        4         0.952189\n",
      "        5         0.976127\n",
      "Dashen  1         0.995137\n",
      "        2         0.957596\n",
      "        3         0.997640\n",
      "        4         0.974137\n",
      "        5         0.984752\n",
      "Name: sentiment_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sentiment by bank and rating\n",
    "print(df.groupby(['bank', 'rating'])['sentiment_score'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
